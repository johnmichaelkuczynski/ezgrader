Project Overview
This project is a desktop application that serves as a pure interface between professors and language models (specifically OpenAI, Anthropic, and Perplexity) for grading student assignments. The application functions exclusively as a direct pass-through that allows professors to submit assignment prompts and student work to LLMs for automated grading and feedback without any content intervention, processing, or decision-making by the application itself.

Core Principles
Pure Pass-Through: The app MUST NOT interfere with, process, or modify any content evaluation/generation in any way. It simply facilitates the interaction between the user and the language model with zero internal processing of content.

Zero Content Decisions: The app must not make any executive decisions about how content is structured, formatted, or organized. It must display LLM responses in their raw, unmodified form.

Immediate AI Detection: As soon as a student paper is uploaded or pasted, it must automatically display an AI-detection score via the external GPTZero API.

Multi-Format Support: All input boxes must support file upload with drag-and-drop functionality for PDF, DOCX, and TXT files.

Content Display: When files are uploaded, their content must be visible in the relevant boxes (not just loaded invisibly).

Clear Functional Separation: The interface must have 5 clearly defined areas with specific purposes.

Replit's Limited Role
Replit serves exclusively as:

A neutral UI/UX platform for connecting professors to external AI services

A visual container for API handoffs between users and LLMs

A display mechanism for showing inputs/outputs from third-party services

Replit DOES NOT:

Perform any content analysis

Apply any algorithms to assignments/feedback

Modify or interpret data between professor ↔ LLM interactions

Store grading logic/rubric weights internally

Make decisions about content structure or format

Assume or enforce any specific grading categories or rubrics

Strict Passthrough Protocol
Replit functions solely as a visual conduit between these elements:

text
Professor → [Inputs] → External LLM APIs → [Outputs] → Professor
Zero data transformation beyond secure transmission

No intermediate processing of prompts/submissions

Third-Party Service Dependency
All substantive functions handled externally:

Grading: OpenAI/Anthropic/Perplexity APIs

AI Detection: GPTZero API

Exemplars: Same LLM provider as grading

Email: SendGrid API

Layout Requirements
The application must have 5 clearly separated functional areas:

Box 1: Assignment Prompt Input

Supports file upload (PDF, DOCX, TXT) via drag-and-drop or browse button

When files are uploaded, their content must be extracted and displayed in this box

Also allows manual text input/typing/pasting

The content serves as instructions to the LLM about the assignment

Box 2: Grading Instructions

Supports file upload (PDF, DOCX, TXT) via drag-and-drop or browse button

When files are uploaded, their content must be extracted and displayed in this box

Also allows manual text input/typing/pasting

Contains criteria for grading, including style, format, and rubric weights

These instructions are passed directly to the LLM without interpretation by Replit

Box 3: Student Submission Upload

Supports file upload (PDF, DOCX, TXT) via drag-and-drop or browse button

When files are uploaded, their content must be extracted and displayed in this box

Also allows manual text input/typing/pasting

Immediately triggers external AI detection upon submission upload/paste

Displays AI-generated probability score with visual indicators (green for human-written, yellow for mixed, red for AI-generated)

Box 4: Grading Results

Displays the UNMODIFIED, RAW grade and comments generated by the LLM exactly as returned

DOES NOT impose any predefined categories, rubric structure, or formatting

DOES NOT attempt to parse, restructure, or organize the LLM's response

The entire LLM response must be displayed as received without Replit's intervention

Provides options to edit feedback, view detailed feedback, email results, etc.

Box 5: Exemplar Generation

Contains sub-sections for reference materials upload and rewrite instructions

Allows users to upload reference materials to provide context to the LLM

Includes functionality to generate exemplary versions of assignments via the external LLM

Displays the unmodified LLM response without any structural assumptions

Replit Override Implementation
To ensure Replit respects the pure pass-through requirements and prevent unwanted structure in the grading results, the following code MUST be implemented:

JavaScript Override Function
javascript
// Force override function - place at the end of your main JS file
function enforcePassthroughInterface() {
  // Target common DOM manipulation timing events
  const events = ['DOMContentLoaded', 'load', 'error', 'readystatechange'];
  
  // Execute multiple times to ensure override sticks after Replit's changes
  events.forEach(event => {
    document.addEventListener(event, () => {
      // Short delay to ensure this runs after Replit's auto-generated code
      setTimeout(() => {
        // Get the container for the grading results
        const gradingResultsContainer = document.getElementById('grading-results') || 
                                       document.querySelector('.grading-results') || 
                                       document.querySelector('[data-testid="grading-results"]');
                                       
        if (gradingResultsContainer) {
          // Store the original raw LLM response if it exists
          const originalResponse = localStorage.getItem('raw_llm_response');
          
          // Clear any structured content Replit added
          gradingResultsContainer.innerHTML = '';
          
          // Create a pure container for raw output
          const rawOutputContainer = document.createElement('div');
          rawOutputContainer.id = 'raw-llm-output';
          rawOutputContainer.className = 'raw-output-container';
          
          // Display the raw LLM response
          if (originalResponse) {
            rawOutputContainer.textContent = originalResponse;
          } else {
            rawOutputContainer.textContent = 'Waiting for LLM response...';
          }
          
          gradingResultsContainer.appendChild(rawOutputContainer);
          
          console.log('OVERRIDE: Enforced pure pass-through interface');
        }
      }, 300); // Delay ensures this runs after Replit's modifications
    });
  });
  
  // Set up observer to continuously enforce override
  const observer = new MutationObserver((mutations) => {
    mutations.forEach((mutation) => {
      if (mutation.type === 'childList' || mutation.type === 'attributes') {
        enforcePassthroughInterface();
      }
    });
  });
  
  // Start observing the entire document
  observer.observe(document.body, { 
    childList: true, 
    subtree: true,
    attributes: true 
  });
}

// Execute the override function
enforcePassthroughInterface();
API Response Interception
javascript
// Intercept and preserve the raw LLM response
async function handleLLMResponse(response) {
  try {
    const rawResponse = await response.text();
    
    // Store the raw response for the override function
    localStorage.setItem('raw_llm_response', rawResponse);
    
    // Display raw response immediately
    const rawOutputContainer = document.getElementById('raw-llm-output');
    if (rawOutputContainer) {
      rawOutputContainer.textContent = rawResponse;
    }
    
    return rawResponse;
  } catch (error) {
    console.error('Error handling LLM response:', error);
  }
}
CSS Override
css
/* Force override Replit's styling */
.rubric-breakdown, 
[data-testid="rubric-breakdown"],
.predefined-category,
[data-testid="predefined-category"] {
  display: none !important;
}

.raw-output-container {
  white-space: pre-wrap;
  font-family: monospace;
  background-color: #f8f9fa;
  padding: 15px;
  border: 1px solid #ddd;
  border-radius: 5px;
  overflow-y: auto;
  max-height: 500px;
}
Implementation Notes
These code snippets MUST be included in the project to prevent Replit from imposing unwanted structure

The JavaScript override function must run after page load to counteract any automatic structuring

The API call must use the handleLLMResponse function to preserve the raw LLM output

The code continuously monitors DOM changes to override any attempts by Replit to restructure content

This solution ensures the application displays raw LLM responses without any predefined categories or structure

Technical Requirements
Document Processing

The system must process documents larger than 800 words in sequential chunks

Must extract text from PDFs, DOCX, and TXT files and display content in the appropriate boxes

File upload areas must visually indicate when files are being dragged over

When a file is uploaded to any box, its textual content must be immediately visible in that box

Extraction is limited to obtaining raw text only, with no analysis or modification

AI Detection Integration

Uses GPTZero API for AI content detection (requires GPTZERO_API_KEY)

Must show a visual progress bar during analysis

Results must display probability percentage and color-coded indicators:

Green (0-30%): Likely human-written

Yellow (31-70%): Possibly AI-assisted

Red (71-100%): Likely AI-generated

Detection must trigger automatically upon submission upload/paste if text length > 100 characters

Detection results must be prominently displayed alongside the submission

The correct API endpoint must be used (/v2/predict/text, not /v2/predict)

All detection is performed externally with Replit only displaying results

LLM Integration

Must support multiple LLM providers:

OpenAI (requires OPENAI_API_KEY)

Anthropic (requires ANTHROPIC_API_KEY)

Perplexity (requires PERPLEXITY_API_KEY)

Other models can be added in the future

The user must be able to select different LLMs for different tasks

Each LLM integration must include configuration options for:

Temperature setting

System prompt customization

Model selection (e.g., gpt-4o for OpenAI, claude-3-7-sonnet-20250219 for Anthropic)

The application must securely store API keys as environment variables

Must provide clear error messages when API keys are missing or invalid

Must send the assignment prompt, grading instructions, and student submission to the selected LLM without any preprocessing or modification

Must display LLM responses exactly as received without any attempt to parse or structure the content

Display Implementation

All HTML/UI elements should be generated dynamically based on the raw response from the LLM API

Zero processing logic that affects content structure

The application should merely render whatever text/formatting is returned by the external service

Loading states must explicitly name the third-party service:

"Waiting for Anthropic Claude-3 response..."

"Analyzing via GPTZero API..."

Email Integration

Includes SendGrid email integration for sharing graded papers (requires SENDGRID_API_KEY)

Should format feedback appropriately for email delivery

Email feature must include:

Configurable sender email address

Student email address input

Properly formatted grade and feedback in the email body

Options to include/exclude detailed feedback

The email must contain the unmodified LLM output

User Experience & Visual Design

Clean, professional, and attractive interface with proper spacing and alignment

Clear visual distinction between the 5 functional areas using color coding:

Box 1: Primary color scheme (Assignment Prompt)

Box 2: Orange/amber scheme (Grading Instructions)

Box 3: Blue scheme (Student Submission)

Box 4: Green scheme (Grading Results)

Box 5: Purple scheme (Exemplar Generation)

Consistent styling across all interface elements with attention to detail

Visual feedback during processing operations (loading spinners, progress bars)

Clear error handling with informative messages

Responsive design that works well on different screen sizes

Properly styled typography with clear hierarchy (headings vs. body text)

High contrast text for readability

Properly sized clickable elements

Visual indicators for drag-and-drop functionality

All functional boxes must display: "[External Service] Processing - Replit acts as display layer only"

Additional Notes
Current implementation handles one student at a time (batch grading will be added later)

Reference materials are optional but enhance grading accuracy by providing context to the LLM

The exemplar generation feature should use the same LLM provider as the grading functionality

The interface should function like a terminal window displaying API output, not a form with predefined fields expecting specific data structures