For an explanation to be good isn’t for it to be correct. Sometimes the right explanations are bad ones. A story will make this clear. I’m on a bus. The bus driver is smiling. A mystery! “What on Earth does he have to smile about?” I ask myself. His job is so boring, and his life must therefore be such a horror.” But then I remember that, just a minute ago, a disembarking passenger gave him fifty $100 bills as a tip. So I have my explanation: “he just came into a lot of money.”
But here is the very different explanation tendered by my seatmate Gus, who, in addition to being unintelligent, is also completely insane. “The bus-driver is a CIA assassin. This morning he killed somebody who, by coincidence, had the name ‘Benjamin Franklin.’ Benjamin Franklin (the statesman, not the murder victim) is on the $100 bill. So when the bus driver saw those bills, he immediately thought of that morning’s murder. The murder was a particularly enjoyable one; the bus driver had a chance to try out some innovative techniques. So, on being given the fifty $100 bills, the bus driver was reminded of that happy experience.” That, my seat-mate believes, is why the bus driver is smiling. The bus driver is indifferent to the fact that he is now richer by $5,000 than he was before. (He’s not a materialistic man. Plus, the CIA pays him a huge salary. $5,000 is nothing to him.)
 
Gus and I have access to the same empirical data. (Gus hasn’t read the bus driver’s diary; he doesn’t know the bus driver any more intimately than I do; and so on.) And Gus doesn’t have some sort of psychic gift that would give him access to otherwise unknowable facts about the bus driver’s mind that would legitimize his explanation. Indeed, a belief that he has such a gift isn’t even among Gus’s many delusions. Nor does he have any good reason—even if, for argument’s sake, one allows his delusions and hallucinations to count as good reasons—to believe that he has such a gift. So given the entirety of the data at our disposal, Gus’s explanation is a bad one. The only evidence in favor of Gus’s theory is that the bus driver started smiling upon being given the money.
But Gus is right. His explanation is correct down to the last detail.
Given that it turned out to be correct, should we say that, despite first appearances, Gus’s explanation is not a bad one? No! It’s a datum that it’s bad. It’s a bad explanation that turned out to be correct. Thus, for an explanation to be a good one isn’t for it to be correct.
But a short extension of our story illustrates the even stronger principle that for an explanation to be a good one isn’t even for it to be likely to be correct. Let W be the real world and let W* be a hypothetical world where we have the exact same experiences that we have in W, but in which the Gus’s of the world are always right. In W*, it’s because Santa Claus is personally delivering gifts to millions of people that they suddenly appear in living rooms round the globe; it isn’t because hard-working parents purchased them. In W*, your keys are missing because stealthy gnomes took them; it isn’t because you drunkenly threw them in the incinerator. And so on. In W*, the right explanations are the ones that, in our world, are extremely bad ones. The data on the basis of which those hypotheses are held in W* (so far as those hypotheses are held) is identical with the data on the basis of which they’re held here (same qualification). But in W*, they’re right, and the good explanations—the logical, sane, well-supported explanations—that they compete with are always wrong. So, in W*, good explanations aren’t even likely to lead to the truth. So there’s no inherent connection between an explanation’s being good and its being true: goodness (in the explanatory sense) cannot be identified with, or even understood in terms of, truth-conduciveness.
Explanatory goodness is a relationship, not between explanations and reality, but between explanation and data. The relations that hold in W* between theory and data coincide with those holding in W. That’s why the ones that are wrong in W* are no less good on that account. What is it that, in W*, makes wrong explanations be good? In general, what is the relationship that good theories bear with respect to the data?
